{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = 'data'\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomRotation(10),       # Randomly rotate images by 10 degrees\n",
    "    transforms.RandomCrop(32, padding=4),  # Randomly crop images with padding\n",
    "    transforms.ToTensor(),               # Convert images to tensor format\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(root=ROOT_PATH, download=True, train=True, transform=transform_augmentation)\n",
    "eval_dataset = CIFAR100(root=ROOT_PATH, train=False, transform=transform)\n",
    "\n",
    "# train_dataset = CIFAR10(root=ROOT_PATH, download=True, train=True, transform=transform)\n",
    "# eval_dataset = CIFAR10(root=ROOT_PATH, train=False, transform=transform)\n",
    "\n",
    "train_data_loader = DataLoader(dataset=train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_data_loader = DataLoader(dataset=eval_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv2 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(128)\n",
    "        self.pool1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.conv3 = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(256)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = torch.nn.Dropout(0.25)\n",
    "        self.fc1 = torch.nn.Linear(8*8*256, 1024)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = torch.nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(1024, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(-1, 8*8*256)\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = ConvNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(CNN_model.parameters(), lr= learning_rate)\n",
    "n_steps = len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/100], Loss: 3.2833\n",
      "End of Epoch 1, Average Loss: 3.6223\n",
      "Epoch [2/20], Step [100/100], Loss: 2.8808\n",
      "End of Epoch 2, Average Loss: 3.0146\n",
      "Epoch [3/20], Step [100/100], Loss: 2.5716\n",
      "End of Epoch 3, Average Loss: 2.7093\n",
      "Epoch [4/20], Step [100/100], Loss: 2.4733\n",
      "End of Epoch 4, Average Loss: 2.5372\n",
      "Epoch [5/20], Step [100/100], Loss: 2.3421\n",
      "End of Epoch 5, Average Loss: 2.3929\n",
      "Epoch [6/20], Step [100/100], Loss: 2.1844\n",
      "End of Epoch 6, Average Loss: 2.2884\n",
      "Epoch [7/20], Step [100/100], Loss: 2.3236\n",
      "End of Epoch 7, Average Loss: 2.2037\n",
      "Epoch [8/20], Step [100/100], Loss: 2.2170\n",
      "End of Epoch 8, Average Loss: 2.1348\n",
      "Epoch [9/20], Step [100/100], Loss: 1.9838\n",
      "End of Epoch 9, Average Loss: 2.0714\n",
      "Epoch [10/20], Step [100/100], Loss: 1.9912\n",
      "End of Epoch 10, Average Loss: 2.0088\n",
      "Epoch [11/20], Step [100/100], Loss: 1.9953\n",
      "End of Epoch 11, Average Loss: 1.9536\n",
      "Epoch [12/20], Step [100/100], Loss: 1.8299\n",
      "End of Epoch 12, Average Loss: 1.9119\n",
      "Epoch [13/20], Step [100/100], Loss: 1.8398\n",
      "End of Epoch 13, Average Loss: 1.8570\n",
      "Epoch [14/20], Step [100/100], Loss: 1.7821\n",
      "End of Epoch 14, Average Loss: 1.8275\n",
      "Epoch [15/20], Step [100/100], Loss: 1.8329\n",
      "End of Epoch 15, Average Loss: 1.7782\n",
      "Epoch [16/20], Step [100/100], Loss: 1.7297\n",
      "End of Epoch 16, Average Loss: 1.7454\n",
      "Epoch [17/20], Step [100/100], Loss: 1.8674\n",
      "End of Epoch 17, Average Loss: 1.7065\n",
      "Epoch [18/20], Step [100/100], Loss: 1.7427\n",
      "End of Epoch 18, Average Loss: 1.6888\n",
      "Epoch [19/20], Step [100/100], Loss: 1.8176\n",
      "End of Epoch 19, Average Loss: 1.6396\n",
      "Epoch [20/20], Step [100/100], Loss: 1.5950\n",
      "End of Epoch 20, Average Loss: 1.6102\n"
     ]
    }
   ],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "optimizer = torch.optim.Adam(CNN_model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = CNN_model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_steps}], Loss: {loss.item():.4f}')\n",
    "    avg_loss = total_loss / n_steps\n",
    "    print(f'End of Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after epoch 20: 55.98%\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = evaluate_model(CNN_model, eval_data_loader)\n",
    "print(f'Validation Accuracy after epoch {epoch+1}: {validation_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN_model, 'CIFAR100_CNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
